#(1) Write a function that multiplies all consecutively decreasing numbers between a maximum and a minimum supplied as arguments. (Like a factorial, but not necessarily going all the way to 1). This calculation would look like

#max * max-1 * max-2 * ... * min

#(2) Using the function you wrote in (1), write a function that calculates the binomial coefficient (see Definition 1.4.12 in the probability reading). Actually, do this twice. The first time (2a) calculate all factorials fully. Now re-write the function and cancel as many terms as possible so you can avoid unnecessary multiplication (see the middle expression in Theorem 1.4.13).

#(3) Try calculating different binomial coefficients using both the functions from (2a) and (2b) for different values of n and k. Try some really big values there is a noticeable difference in speed between the (2a) and (2b) function. Which one is faster? By roughly how much?

#(4) Use either function (2a) or (2b) to write a function that calculates the probability of k successes in n Bernoulli trials with probability p. This is called the Binomial(n,p) distribution. See Theorem 3.3.5 for the necessary equation. [Hint: pow(x,y) returns x^y (x raised to the power of y).]

#(5) Now write a function to sample from an arbitrary discrete distribution. This function should take two arguments. The first is a list of arbitrarily labeled events and the second is a list of probabilities associated with these events. Obviously, these two lists should be the same length.

#---> Sampling sites from an alignment <---

#Imagine that you have a multiple sequence alignment with two kinds of sites. One type of site pattern supports the monophyly of taxon A and taxon B. The second type supports the monophyly of taxon A and taxon C.

#(6) For an alignment of 400 sites, with 200 sites of type 1 and 200 of type 2, sample a new alignment (a new set of site pattern counts) with replacement from the original using your function from (5). Print out the counts of the two types.

#(7) Repeat (6) 100 times and store the results in a list.

#(8) Of those 100 trials, summarize how often you saw particular proportions of type 1 vs. type 2. 

#(9) Calculate the probabilities of the proportions you saw in (8) using the binomial probability mass function (PMF) from (4).

#(10) Compare your results from (8) and (9).

#(11) Repeat 7-10, but use 10,000 trials.

import random
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import functools
import operator
functools.reduce(operator.mul, [1,2,3,4,5,6], 1)



 
def fact(k,n): 
  out=1
  for i in range(k,n-1,-1):
      out=out*i
  return out
      
   
   
def factorial(m): #make a function that calculates the factorial for a number to be used in the next function
    if m ==1:
        return m
    else:
        return m*factorial(m-1)   

def binCoeff(n,k): #calculate the bin coefficient with equation 1.4.13
      return fact(n,(n-k+1))/fact(k,1)
 
    
 
    
  
def bernoulli(p,n,k): #calculate probability of k successes in n trials with p probability
	out = binCoeff(n,k)*pow(p,n)*pow((1-p),(n-k))
	return out

    
def binomPMF(k,n,p):
    """
    This function returns the probability mass of k successes for a binomial distribution with n trials and a
    probability of success given by p.
    """
    return binCoeff(n,k)*pow(p,k)*pow((1-p),(n-k))
# set up a list with all relevant values of p
P=range(0,100,5)

P=[int(b)/100 for b in P]
    



# Calculate the likelihood scores for these values of p, in light of the data you've collected

def likelihood(k,n,p):
   lik= binomPMF(k,n,p)/binCoeff(k,n)
   return lik

likes=[]
 
for val in P:
    num=likelihood(4,5,val)
    likes.append(num)
    
 
 
