#(1) Write a function that multiplies all consecutively decreasing numbers between a maximum and a minimum supplied as arguments. (Like a factorial, but not necessarily going all the way to 1). This calculation would look like

#max * max-1 * max-2 * ... * min

#(2) Using the function you wrote in (1), write a function that calculates the binomial coefficient (see Definition 1.4.12 in the probability reading). Actually, do this twice. The first time (2a) calculate all factorials fully. Now re-write the function and cancel as many terms as possible so you can avoid unnecessary multiplication (see the middle expression in Theorem 1.4.13).

#(3) Try calculating different binomial coefficients using both the functions from (2a) and (2b) for different values of n and k. Try some really big values there is a noticeable difference in speed between the (2a) and (2b) function. Which one is faster? By roughly how much?

#(4) Use either function (2a) or (2b) to write a function that calculates the probability of k successes in n Bernoulli trials with probability p. This is called the Binomial(n,p) distribution. See Theorem 3.3.5 for the necessary equation. [Hint: pow(x,y) returns x^y (x raised to the power of y).]

#(5) Now write a function to sample from an arbitrary discrete distribution. This function should take two arguments. The first is a list of arbitrarily labeled events and the second is a list of probabilities associated with these events. Obviously, these two lists should be the same length.

#---> Sampling sites from an alignment <---

#Imagine that you have a multiple sequence alignment with two kinds of sites. One type of site pattern supports the monophyly of taxon A and taxon B. The second type supports the monophyly of taxon A and taxon C.

#(6) For an alignment of 400 sites, with 200 sites of type 1 and 200 of type 2, sample a new alignment (a new set of site pattern counts) with replacement from the original using your function from (5). Print out the counts of the two types.

#(7) Repeat (6) 100 times and store the results in a list.

#(8) Of those 100 trials, summarize how often you saw particular proportions of type 1 vs. type 2. 

#(9) Calculate the probabilities of the proportions you saw in (8) using the binomial probability mass function (PMF) from (4).

#(10) Compare your results from (8) and (9).

#(11) Repeat 7-10, but use 10,000 trials.

import random
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt
import functools
import operator
functools.reduce(operator.mul, [1,2,3,4,5,6], 1)



def fact(k,n): 
  out=1
  for i in range(k,n-1,-1):
      out=out*i
  return out
      
   
   


def binCoeff(n,k): #calculate the bin coefficient with equation 1.4.13
      return fact(n,(n-k+1))/fact(k,1)
 
    
    
def binomPMF(k,n,p):
    """
    This function returns the probability mass of k successes for a binomial distribution with n trials and a
    probability of success given by p.
    """
    return binCoeff(n,k)*pow(p,k)*pow((1-p),(n-k))
# set up a list with all relevant values of p
P=range(0,101,5)

P=[b/100 for b in P]
    



# Calculate the likelihood scores for these values of p, in light of the data you've collected

def likelihood(k,n,p):
   lik = binomPMF(k,n,p)
   return lik

likes=[]
 
for val in P:
    num=likelihood(12,20,val)
    likes.append(num)
    
 
maxlik = max(likes)
 
print "the maximum likelihood is" + str(maxlik)
 
list[likes.index(maxlik)]
 
ratio=[]
for val in likes:
     ratio.append(val/maxlik)
 


# Write a function that finds the ML value of p for a binomial, given k and n.

def MLVal(k,n):
    diff=0.1
    pCurr=0.5 #start at a random spot between 0 and 1
    currLik = likelihood(k,n,pCurr) #calculate the likelihood of the p
    pVals=[] #set up a list for the p values
    MLVals=[] # set up a list for the ML values
    upLik = likelihood(k,n,(pCurr+diff))
    downLik = likelihood(k,n,(pCurr-diff)) 
    while upLik>currLik:
        currLik=likelihood(k,n,pCurr+diff)
        pCurr=pCurr+0.1
    pVals.append(pCurr)
    MLVals.append(currLik)
    while downLik>currLik:
        currLik=likelihood(k,n,pCurr-diff)
        pCurr=pCurr-0.1   
    pVals.append(pCurr)
    MLVals.append(currLik)
    likArray=(pVals,MLVals)
    maxLik=max(MLVals)
    for i in range(0,len(MLVals)):
        if MLVals[i]==maxLik:
            k=(pVals[i])        
    return "the best p is ",k," with a likelihood of",maxLik
            
MLVal(1,300)








"""
In the exercise above, you tried to find an intuitive cutoff for likelihood ratio
scores that would give you a reasonable interval in which to find the true value of 
p. Now, we will empirically determine one way to construct such an interval. To do 
so, we will ask how far away from the true value of a parameter the ML estimate 
might stray. Use this procedure: (1) start with a known value for p, (2) simulate
a bunch of datasets, (3) find ML parameter estimates for each simulation, and then 
(4) calculate the likelihood ratios comparing the true parameter values and the ML
estimates. When you do this, you will be constructing a null distribution of
likelihood ratios that might be expected if the value of p you picked in (1)
was true. Note that the ML values for these replicates are very often greater than
L(true value of P), because the ML value can only ever be >= L(true value). Once 
you have this distribution, find the likelihood ratio cutoff you need to ensure 
that the probability of seeing an LR score that big or greater is <= 5%. 
"""

# Set a starting, true value for p

trueP = 

# Simulate 1,000 datasets of 200 trials from a binomial with this p
# If you haven't already done so, you'll want to import the binom class from scipy:
# from scipy.stats import binom
# binom.rvs(n,p) will then produce a draw from the corresponding binomial.



# Now find ML parameter estimates for each of these trials



# Calculate likelihood ratios comparing L(trueP) in the numerator to the maximum
# likelihood (ML) in the denominator. Sort the results and find the value
# corresponding to the 95th percentile.



# Now, convert the likelihood ratios (LRs) to -2ln(LRs) values.
# Find the 95th percentile of these values. Compare these values to this table:
# https://people.richland.edu/james/lecture/m170/tbl-chi.html. In particular, look
# at the 0.05 column. Do any of these values seem similar to the one you calculated?
# Any idea why that particular cell would be meaningful?



# Based on your results (and the values in the table), what LR statistic value 
# [-2ln(LR)] indicates that a null value of p is far enough away from the ML value
# that an LR of that size is <=5% probable if that value of p was true?



# Using this cutoff, what interval might you report for the 5- and 20-trial data
# sets above?



# We've talked in previous classes about two ways to interpret probabilities. Which
# interpretation are we using here to define these intervals?

 
 
